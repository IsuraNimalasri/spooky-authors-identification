{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pre-work</h1>\n",
    "\n",
    "On my laptop I can't run the code for the entire dataframe, so it's going to be on the half and we'll have to run it at the library over more powerful laptop. Unless one of us has a powerful enough laptop.\n",
    "Other options:\n",
    "- run on Google Cloud\n",
    "- use Columbia's Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip3 install nltk\n",
    "#!pip3 install seaborn\n",
    "#!pip3 install langdetect\n",
    "#!pip3 install wordcloud\n",
    "#!pip3 install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#from wordcloud import wordcloud, STOPWORDS\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, FreqDist\n",
    "from nltk.data import load\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn import metrics, model_selection, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier)\n",
    "from sklearn.metrics import log_loss, fbeta_score, make_scorer, confusion_matrix, roc_curve\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "\n",
    "from sklearn import datasets # toy datasets\n",
    "\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Processing functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Normalization Function</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Normalization over number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_word(var):\n",
    "    \"\"\"Returns number of words.\"\"\"\n",
    "    words = nltk.Text(word_tokenize(((var))))\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Normalization by number of Sentences</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_sentence(var):\n",
    "    \"\"\"Returns number of sentences.\"\"\"\n",
    "    sentences = nltk.Text(sent_tokenize(var))\n",
    "    return len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Normalization by number of Characters</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalization_character(var):\n",
    "    \"\"\"Returns number of characters.\"\"\"\n",
    "    return len(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cleaning Function</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning(var):\n",
    "    \"\"\"Take a string. Returns a string with only lowercase letters and the space between words.\"\"\"\n",
    "    plain_string = \"\"\n",
    "    for x in var:\n",
    "        x = x.lower()\n",
    "        if (('a' <= x and x <= 'z') or x == ' '):\n",
    "            plain_string += x\n",
    "        elif x == '\\'': # any apostrophes(') are replaced by a space \n",
    "            plain_string += ' '\n",
    "    while '  ' in plain_string: # any multiple spaces are replaced by a single space\n",
    "        plain_string = plain_string.replace('  ', ' ')\n",
    "    return plain_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creation of the dataframes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "# data must be in same folder\n",
    "\n",
    "author_list = ['EAP', 'HPL', 'MWS']\n",
    "train.text= train.text.astype(str) # casts the type of the text column to str\n",
    "train.author = pd.Categorical(train.author)\n",
    "\n",
    "train = train[0:400]  # size reduction for coding\n",
    "\n",
    "train_back_up = train.copy() # back-up used to define future dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This process, however, afforded me no means of ascertaining the dimensions of my dungeon; as I might make its circuit, and return to the point whence I set out, without being aware of the fact; so perfectly uniform seemed the wall.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a test cell\n",
    "test = train['text'][0]\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Word Clouds</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# full text from the authors as an array\n",
    "eap = train[train.author==\"EAP\"][\"text\"].values\n",
    "hpl = train[train.author==\"HPL\"][\"text\"].values\n",
    "mws = train[train.author==\"MWS\"][\"text\"].values\n",
    "\n",
    "# full text from the authors as a string\n",
    "eap_s = \" \".join(eap)\n",
    "hpl_s = \" \".join(hpl)\n",
    "mws_s = \" \".join(mws)\n",
    "\n",
    "# full PLAIN text (i.e. no capital and punctuation) from the authors as a string\n",
    "eap_s_c = cleaning(eap_s)\n",
    "hpl_s_c = cleaning(hpl_s)\n",
    "mws_s_c = cleaning(mws_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Read the whole text\\nlist_text = [eap_s_c, hpl_s_c, mws_s_c]\\n\\n# read the mask image\\n# taken from http://www.stencilry.org/\\neap_mask = np.array(Image.open(\"eap_mask.jpg\"))\\nhpl_mask = np.array(Image.open(\"hpl_mask.jpg\"))\\nmws_mask = np.array(Image.open(\"mws_mask.jpg\"))\\nlist_mask = [eap_mask, hpl_mask, mws_mask]\\n\\nstopwords = set(STOPWORDS)\\n\\nfor i in range(3):\\n    wc = WordCloud(background_color=\"white\", max_words=2000, mask=list_mask[i],\\n                   stopwords=stopwords)\\n    # generate word cloud\\n    wc.generate(list_text[i])\\n    # show\\n    plt.imshow(wc, interpolation=\\'bilinear\\')\\n    plt.title(\\'Wordcloud of author \\' + author_list[i])\\n    plt.axis(\"off\")\\n    plt.figure()\\n    # store to file\\n    wc.to_file(\"{}_wordcloud.png\".format(author_list[i]))\\n    \\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Read the whole text\n",
    "list_text = [eap_s_c, hpl_s_c, mws_s_c]\n",
    "\n",
    "# read the mask image\n",
    "# taken from http://www.stencilry.org/\n",
    "eap_mask = np.array(Image.open(\"eap_mask.jpg\"))\n",
    "hpl_mask = np.array(Image.open(\"hpl_mask.jpg\"))\n",
    "mws_mask = np.array(Image.open(\"mws_mask.jpg\"))\n",
    "list_mask = [eap_mask, hpl_mask, mws_mask]\n",
    "\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "for i in range(3):\n",
    "    wc = WordCloud(background_color=\"white\", max_words=2000, mask=list_mask[i],\n",
    "                   stopwords=stopwords)\n",
    "    # generate word cloud\n",
    "    wc.generate(list_text[i])\n",
    "    # show\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.title('Wordcloud of author ' + author_list[i])\n",
    "    plt.axis(\"off\")\n",
    "    plt.figure()\n",
    "    # store to file\n",
    "    wc.to_file(\"{}_wordcloud.png\".format(author_list[i]))\n",
    "    \n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Splitting the training set.</h1>\n",
    "<br>\n",
    "Because we have only two dataset, one for training and the other for the Kaggle test. We need to split our 'Kaggle training' set (called t0) into training (called tr1) (in the sense of the training of our predictive model) and testing set (called ts1) (in the sense of testing our models, and not be tested by Kaggle !).<br>\n",
    "<br>\n",
    "We shall notice we will choose the best classifier only with the tr1 DataSet. Then, we will test this classifier with ts1 to see if we over-fitted over tr1.<br>\n",
    "<br>\n",
    "\n",
    "Once we havechosen the classifier and checked for over-fitting, we will train the chosen classifier over tr1 and ts1. We will use this to predict over the \"Kaggle Test Dataset\" and create our submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t0 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "225\n",
      "75\n",
      "0.75\n",
      "0.25\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "tr1, ts1 = train_test_split(t0, test_size=20/80)\n",
    "# 20% to tr1 and 80% to ts1\n",
    "\n",
    "print(len(t0))\n",
    "print(len(tr1))\n",
    "print(len(ts1))\n",
    "print(len(tr1) / len(t0))\n",
    "print(len(ts1) / len(t0))\n",
    "print((len(tr1) / len(t0)) + (len(ts1) / len(t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>id03833</td>\n",
       "      <td>The ex queen gives me Idris; Adrian is totally...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>id12835</td>\n",
       "      <td>As the sailor looked in, the gigantic animal h...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>id06312</td>\n",
       "      <td>I dared, I conquered them all, till now I have...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>id23496</td>\n",
       "      <td>\"No\" said the Baron, turning abruptly toward t...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id22965</td>\n",
       "      <td>A youth passed in solitude, my best years spen...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text author\n",
       "90   id03833  The ex queen gives me Idris; Adrian is totally...    MWS\n",
       "272  id12835  As the sailor looked in, the gigantic animal h...    EAP\n",
       "66   id06312  I dared, I conquered them all, till now I have...    MWS\n",
       "276  id23496  \"No\" said the Baron, turning abruptly toward t...    EAP\n",
       "5    id22965  A youth passed in solitude, my best years spen...    MWS"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>id15797</td>\n",
       "      <td>He also cut timber and began to repair the unu...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>id10265</td>\n",
       "      <td>Time, place, and circumstances rendered it a m...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>id25019</td>\n",
       "      <td>And quivering awhile among the draperies of th...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>id17128</td>\n",
       "      <td>Not any more does he long for the magic of far...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>id15440</td>\n",
       "      <td>There was Ferdinand Fitz Fossillus Feltspar.</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text author\n",
       "200  id15797  He also cut timber and began to repair the unu...    HPL\n",
       "282  id10265  Time, place, and circumstances rendered it a m...    EAP\n",
       "93   id25019  And quivering awhile among the draperies of th...    EAP\n",
       "171  id17128  Not any more does he long for the magic of far...    HPL\n",
       "294  id15440       There was Ferdinand Fitz Fossillus Feltspar.    EAP"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Feature Engineering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Meta Features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Average sentence length (in characters)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length_character(var):\n",
    "    \"\"\"Takes a string returns an int (average sentence length in characters).\"\"\"\n",
    "    return len(var) / normalization_sentence(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Average sentence length (in words)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length_sentence(var):\n",
    "    \"\"\"Takes a string and returns an int (average sentence length in words).\"\"\"\n",
    "    return len(var.split()) / normalization_sentence(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Average characters per word</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def length_word(var):\n",
    "    \"\"\"Takes a string and returns an int (average characters per word). Excludes punctuations.\"\"\"\n",
    "    return len(var.split()) / normalization_word(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Punctuation density</h3>\n",
    "Now we take into consideration differences in punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_coma(var):\n",
    "    \"\"\"Takes a string and returns the ratio of punctuations to characters.\"\"\"\n",
    "    cpunc = 0\n",
    "    for x in var:\n",
    "        if x == ',':\n",
    "            cpunc += 1\n",
    "    return cpunc / normalization_character(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_point(var):\n",
    "    \"\"\"Takes a string and returns the ratio of periods(.) to characters.\"\"\"\n",
    "    cpunc = 0\n",
    "    for x in var:\n",
    "        if x == '.':\n",
    "            cpunc += 1\n",
    "    return cpunc / normalization_character(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_colon(var):\n",
    "    \"\"\"Takes a string and returns the ratio of colons(:) to characters.\"\"\"\n",
    "    cpunc = 0\n",
    "    for x in var:\n",
    "        if x == ':':\n",
    "            cpunc += 1\n",
    "    return cpunc / normalization_character(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_semicolon(var):\n",
    "    \"\"\"Takes a string and returns the ratio of semicolons(;) to characters.\"\"\"\n",
    "    cpunc = 0\n",
    "    for x in var:\n",
    "        if x == ';':\n",
    "            cpunc += 1\n",
    "    return cpunc / normalization_character(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_interro(var):\n",
    "    \"\"\"Takes a string and returns the ratio of question marks(?) to characters.\"\"\"\n",
    "    cpunc = 0\n",
    "    for x in var:\n",
    "        if x == '?':\n",
    "            cpunc += 1\n",
    "    return cpunc / normalization_character(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_expl(var):\n",
    "    \"\"\"Takes a string and returns the ratio of exclamation points(!) to characters.\"\"\"\n",
    "    cpunc = 0\n",
    "    for x in var:\n",
    "        if x == '!':\n",
    "            cpunc += 1\n",
    "    return cpunc / normalization_character(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Percentage of unique words per sentence</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocabulary_sentence(var):\n",
    "    \"\"\"Takes a string and returns the ratio of different words to all words.\"\"\"\n",
    "    var = nltk.Text(sent_tokenize(var))\n",
    "    vocabulary_list = []\n",
    "    for c in var:\n",
    "        if normalization_word(c) != 0:\n",
    "            vacabulary_count_sentence = len({x.lower() for x in word_tokenize(cleaning(c))})\n",
    "            vocabulary_list.append(vacabulary_count_sentence / normalization_word(c))\n",
    "    return np.mean(vocabulary_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79527972027972038"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just a test cell\n",
    "\n",
    "vocabulary_sentence(\"Wow, this is a bad one. On Macs running the latest version of High Sierra (10.13.1 (17B48)), it appears that anyone can log in just by putting “root” in the user name field in a certain place. This is a huge, huge problem. Apple will fix it probably within hours but holy moly. Do not leave your Mac unattended\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Stopword percentage</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_stopword(var):\n",
    "    \"\"\"Takes a string and returns the ratio of stopwords to all words.\"\"\"\n",
    "    cs = 0\n",
    "    for x in nltk.Text(word_tokenize(var)):\n",
    "        if x in STOPWORDS:\n",
    "            cs += 1\n",
    "    return cs/normalization_word(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Noun Density</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_noun(var):\n",
    "    \"\"\"Takes a string and returns the ratio of nouns to all words.\"\"\"\n",
    "    l = []\n",
    "    for x in nltk.pos_tag(word_tokenize(var)):\n",
    "        if x[1][0:2] == 'NN': # all noun tags start with NN\n",
    "            l.append(x)\n",
    "    return len(l)/normalization_word(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Verb Density</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_verb(var):\n",
    "    \"\"\"Takes a string and returns the ratio of verbs to all words.\"\"\"\n",
    "    l = []\n",
    "    for x in nltk.pos_tag(word_tokenize(var)):\n",
    "        if x[1][0:2] == 'VB': # all verb tags start with VB\n",
    "            l.append(x)\n",
    "    return len(l)/normalization_word(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Adjective Density</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def density_adjective(var):\n",
    "    \"\"\"Takes a string and returns the ratio of adjectives to all words.\"\"\"\n",
    "    l = []\n",
    "    for x in nltk.pos_tag(word_tokenize(var)):\n",
    "        if x[1][0:2] == 'JJ': # all adjective tags start with JJ\n",
    "            l.append(x)\n",
    "    return len(l) / normalization_word(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Adjective to noun ratio</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjective_to_noun(var):\n",
    "    \"\"\"Takes a string and returns the ratio of adjectives to nouns.\"\"\"\n",
    "    return density_adjective(var) / (density_noun(var) + 0.5) # add 0.5 to avoid division by 0 error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Emphases on Words or Phrases</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_emph(var):\n",
    "    \"\"\"Takes a string and returns the usage count of emphases using double quotes.\"\"\"\n",
    "    emph_trig_words = 'word called the a their my his her for that those like of words'.split() \n",
    "    emph_count = 0\n",
    "    var = var.lower()\n",
    "    for word in emph_trig_words:\n",
    "        emph_count += var.count('{} \"'.format(word))\n",
    "    return emph_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dialogues Breaks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_dial_break(var):\n",
    "    \"\"\"\n",
    "    Takes a string and returns the count of dialogue breaks used.\n",
    "    Example of a dialogue break: (\"D ,\" replied Dupin, \"is a desperate man, and a man of nerve.)\n",
    "    \"\"\"\n",
    "    return var.count(\", \\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dialogues</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_dblqt(var):\n",
    "    \"\"\"Takes a string and returns the count of sets of double quotes\"\"\"\n",
    "    return ceil(var.count('\"')/2) # ceil function rounds up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_dial(var):\n",
    "    \"\"\"\n",
    "    Takes a string and returns the count of dialogues used. Assumption is that if in double quotes but not an\n",
    "    emphasis, then it is a dialogue.\n",
    "    \"\"\"\n",
    "    return count_dblqt(var) - count_emph(var) - count_dial_break(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_to_dial_ratio(var):\n",
    "    \"\"\"Take sa string and returns the ratio of dialogue breaks to dialogues.\"\"\"\n",
    "    if not count_dial(var):\n",
    "        return 0\n",
    "    return count_dial_break(var) / count_dial(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Feminine and Masculine Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_fem(var):\n",
    "    \"\"\"Takes a string and returns the count of feminine words.\"\"\"\n",
    "    fem_words = 'she her woman herself girl women lady queen princess daughter madam madame wife'.split()\n",
    "    fem_count = 0\n",
    "    var = cleaning(var)\n",
    "    for word in var.split():\n",
    "        if word in fem_words:\n",
    "            fem_count += 1\n",
    "    return fem_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_mas(var):\n",
    "    \"\"\"Takes a string and returns the count of masculine words.\"\"\"\n",
    "    mas_words = 'he his man mr himself boy men gentleman gentlemen king prince son sir husband'.split()\n",
    "    mas_count = 0\n",
    "    var = cleaning(var)\n",
    "    for word in var.split():\n",
    "        if word in mas_words:\n",
    "            mas_count += 1\n",
    "    return mas_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fem_to_mas_ratio(var):\n",
    "    \"\"\"Takes a string and returns the ratio of feminine words to masculine words.\"\"\"\n",
    "    fem_count = count_fem(var)\n",
    "    mas_count = count_mas(var)\n",
    "    if fem_count and not mas_count:\n",
    "        fem_mas_ratio = 1\n",
    "    elif not fem_count and not mas_count:\n",
    "        fem_mas_ratio = 0\n",
    "    else:\n",
    "        fem_mas_ratio = fem_count / mas_count\n",
    "    return fem_mas_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>norm_count_emph</th>\n",
       "      <th>norm_count_dial</th>\n",
       "      <th>norm_count_dial_break</th>\n",
       "      <th>norm_break_to_dial_ratio</th>\n",
       "      <th>norm_count_fem</th>\n",
       "      <th>norm_count_mas</th>\n",
       "      <th>norm_fem_to_mas_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EAP</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.176991</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.362832</td>\n",
       "      <td>0.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HPL</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041237</td>\n",
       "      <td>0.783505</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MWS</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.586667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  author                                               text  norm_count_emph  \\\n",
       "0    EAP  This process, however, afforded me no means of...         0.026549   \n",
       "1    HPL  It never once occurred to me that the fumbling...         0.010309   \n",
       "2    MWS  How lovely is spring As we looked from Windsor...         0.000000   \n",
       "\n",
       "   norm_count_dial  norm_count_dial_break  norm_break_to_dial_ratio  \\\n",
       "0         0.176991               0.035398                  0.200000   \n",
       "1         0.041237               0.000000                  0.000000   \n",
       "2         0.066667               0.055556                  0.833333   \n",
       "\n",
       "   norm_count_fem  norm_count_mas  norm_fem_to_mas_ratio  \n",
       "0        0.079646        0.362832               0.219512  \n",
       "1        0.041237        0.783505               0.052632  \n",
       "2        0.488889        0.833333               0.586667  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([['EAP', eap_s], ['HPL', hpl_s], ['MWS', mws_s]])\n",
    "df.columns = ['author', 'text']\n",
    "\n",
    "for f in [count_emph, count_dial, count_dial_break, break_to_dial_ratio, count_fem, count_mas, fem_to_mas_ratio]:\n",
    "    df['norm_' + f.__name__] = df.text.apply(f)\n",
    "    \n",
    "for f in [count_emph, count_dial, count_dial_break, count_fem, count_mas]: # normalization of count_emph, count_dial, and count_dial_break\n",
    "    df['norm_' + f.__name__] = df['norm_' + f.__name__] / df.author.apply(lambda x: len(train[train.author == x]))\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor c in df.columns[2:]:\\n    plt.style.use('seaborn')\\n    sns.barplot(x='author', y=c, data=df)\\n    plt.title('Meta {}'.format(c))\\n    plt.savefig('Meta {}'.format(c))\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for c in df.columns[2:]:\n",
    "    plt.style.use('seaborn')\n",
    "    sns.barplot(x='author', y=c, data=df)\n",
    "    plt.title('Meta {}'.format(c))\n",
    "    plt.savefig('Meta {}'.format(c))\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\\nfem_words = 'her she herself girl woman lady queen daughter madam madame wife women princess'.split()\\n\\nplt.suptitle('Normalized Feminine Word Count', y=1.02)\\n\\nxlmt = 0\\nfor auth in [(eap_s_c, 'EAP'), (hpl_s_c, 'HPL'), (mws_s_c, 'MWS')]:\\n    for word in fem_words:\\n        norm_count = auth[0].count(word) / len(train[train.author == auth[1]])\\n        if norm_count > xlmt:\\n            xlmt = norm_count\\n\\nfor ax in ((ax1, eap_s_c, 'darkblue', 'EAP'), (ax2, hpl_s_c, 'darkgreen', 'HPL'), (ax3, mws_s_c, 'darkred', 'MWS')):\\n    y = np.arange(len(fem_words))\\n    x = [ax[1].count(word) / len(train[train.author == ax[3]]) for word in fem_words]\\n    ax[0].barh(y, x, align='center',\\n            color=ax[2], ecolor='black')\\n    ax[0].set_yticks(y)\\n    ax[0].set_yticklabels(fem_words)\\n    ax[0].invert_yaxis()\\n    ax[0].set_title(ax[3])\\n    ax[0].set_xlim([0, xlmt])\\n    \\nplt.tight_layout()\\nplt.savefig('Meta feminine word count')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "fem_words = 'her she herself girl woman lady queen daughter madam madame wife women princess'.split()\n",
    "\n",
    "plt.suptitle('Normalized Feminine Word Count', y=1.02)\n",
    "\n",
    "xlmt = 0\n",
    "for auth in [(eap_s_c, 'EAP'), (hpl_s_c, 'HPL'), (mws_s_c, 'MWS')]:\n",
    "    for word in fem_words:\n",
    "        norm_count = auth[0].count(word) / len(train[train.author == auth[1]])\n",
    "        if norm_count > xlmt:\n",
    "            xlmt = norm_count\n",
    "\n",
    "for ax in ((ax1, eap_s_c, 'darkblue', 'EAP'), (ax2, hpl_s_c, 'darkgreen', 'HPL'), (ax3, mws_s_c, 'darkred', 'MWS')):\n",
    "    y = np.arange(len(fem_words))\n",
    "    x = [ax[1].count(word) / len(train[train.author == ax[3]]) for word in fem_words]\n",
    "    ax[0].barh(y, x, align='center',\n",
    "            color=ax[2], ecolor='black')\n",
    "    ax[0].set_yticks(y)\n",
    "    ax[0].set_yticklabels(fem_words)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].set_title(ax[3])\n",
    "    ax[0].set_xlim([0, xlmt])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Meta feminine word count')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\\nmas_words = 'he his men man king son himself mr boy gentleman prince sir gentlemen husband mister'.split()\\n\\nplt.suptitle('Normalized Masculine Word Count', y=1.02)\\n\\nxlmt = 0\\nfor auth in [(eap_s_c, 'EAP'), (hpl_s_c, 'HPL'), (mws_s_c, 'MWS')]:\\n    for word in mas_words:\\n        norm_count = auth[0].count(word) / len(train[train.author == auth[1]])\\n        if norm_count > xlmt:\\n            xlmt = norm_count\\n            \\nfor ax in ((ax1, eap_s_c, 'darkblue', 'EAP'), (ax2, hpl_s_c, 'darkgreen', 'HPL'), (ax3, mws_s_c, 'darkred', 'MWS')):\\n    y = np.arange(len(mas_words))\\n    x = [ax[1].count(word) / len(train[train.author == ax[3]]) for word in mas_words]\\n    ax[0].barh(y, x, align='center',\\n            color=ax[2], ecolor='black')\\n    ax[0].set_yticks(y)\\n    ax[0].set_yticklabels(mas_words)\\n    ax[0].invert_yaxis()\\n    ax[0].set_title(ax[3])\\n    ax[0].set_xlim([0, xlmt])\\n    \\nplt.tight_layout()\\nplt.savefig('Meta masculine word count')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=True)\n",
    "mas_words = 'he his men man king son himself mr boy gentleman prince sir gentlemen husband mister'.split()\n",
    "\n",
    "plt.suptitle('Normalized Masculine Word Count', y=1.02)\n",
    "\n",
    "xlmt = 0\n",
    "for auth in [(eap_s_c, 'EAP'), (hpl_s_c, 'HPL'), (mws_s_c, 'MWS')]:\n",
    "    for word in mas_words:\n",
    "        norm_count = auth[0].count(word) / len(train[train.author == auth[1]])\n",
    "        if norm_count > xlmt:\n",
    "            xlmt = norm_count\n",
    "            \n",
    "for ax in ((ax1, eap_s_c, 'darkblue', 'EAP'), (ax2, hpl_s_c, 'darkgreen', 'HPL'), (ax3, mws_s_c, 'darkred', 'MWS')):\n",
    "    y = np.arange(len(mas_words))\n",
    "    x = [ax[1].count(word) / len(train[train.author == ax[3]]) for word in mas_words]\n",
    "    ax[0].barh(y, x, align='center',\n",
    "            color=ax[2], ecolor='black')\n",
    "    ax[0].set_yticks(y)\n",
    "    ax[0].set_yticklabels(mas_words)\n",
    "    ax[0].invert_yaxis()\n",
    "    ax[0].set_title(ax[3])\n",
    "    ax[0].set_xlim([0, xlmt])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('Meta masculine word count')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Building of the Dataframe of Metadata</h3>\n",
    "\n",
    "This is the list of all the meta data we are going to use to train our classifiers. We are also going to use bag of words. This could be modified if we add meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_meta1(dataframe):\n",
    "    \"\"\"Builds a dataframe that shows the author and the first set of meta-data related to the sentence.\"\"\"\n",
    "    df_meta = dataframe.copy()\n",
    "    for f in [count_emph, count_dial, count_dial_break, break_to_dial_ratio, count_fem, count_mas, fem_to_mas_ratio]:\n",
    "        df_meta[f.__name__] = df_meta.text.apply(f)\n",
    "    \n",
    "    del df_meta['text']\n",
    "    if 'author' in df_meta.columns:\n",
    "        del df_meta['author']\n",
    "    \n",
    "    return df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datameta1 = build_meta1(tr1)\n",
    "#datameta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_meta2(dataframe):\n",
    "    \"\"\"Builds a dataframe that shows the author and the other meta-data related to the sentence.\"\"\"\n",
    "    df_meta = dataframe.copy()\n",
    "    list_meta = [length_character,\n",
    "             length_sentence,\n",
    "             length_word,  \n",
    "             vocabulary_sentence,\n",
    "             density_stopword,\n",
    "             density_noun,\n",
    "             density_verb,\n",
    "             density_adjective,\n",
    "             adjective_to_noun,\n",
    "             density_coma,\n",
    "             density_point,\n",
    "             density_colon,\n",
    "             density_semicolon,\n",
    "             density_interro,\n",
    "             density_expl\n",
    "            ]\n",
    "    for f in list_meta:\n",
    "        df_meta[f.__name__] = df_meta.text.apply(f)\n",
    "    return df_meta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatameta2 = build_meta2(tr1)\\ndatameta2\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datameta2 = build_meta2(tr1)\n",
    "datameta2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor c in datameta2.columns[3:]:\\n    plt.style.use('seaborn')\\n    sns.boxplot(x='author', y=c, data=datameta2)\\n    plt.title('Meta {}'.format(c))\\n    plt.savefig('Meta {}'.format(c))\\n    plt.show()\\n    \\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for c in datameta2.columns[3:]:\n",
    "    plt.style.use('seaborn')\n",
    "    sns.boxplot(x='author', y=c, data=datameta2)\n",
    "    plt.title('Meta {}'.format(c))\n",
    "    plt.savefig('Meta {}'.format(c))\n",
    "    plt.show()\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Text Features</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>First Word</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_word_type(sents):\n",
    "    \"\"\"Takes a list of sentences and returns a list of the word type used to start each element.\"\"\"\n",
    "    res = list()\n",
    "    for sent in sents:\n",
    "        typ = nltk.pos_tag(sent.split())\n",
    "        i = 0\n",
    "        j = 0\n",
    "        word = typ[i][0].lower()\n",
    "        while i < len(sent.split()):\n",
    "            if j < len(word) and word[j] >= 'a' and word[j] <= 'z':\n",
    "                res.append(typ[i][1])\n",
    "                break\n",
    "            i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_word(dataframe):\n",
    "    \"\"\"Takes a dataframe and creates a column per word type with a value of 1 on the word type used.\"\"\"\n",
    "    df = dataframe.copy()\n",
    "    elements = ['CC','CD','DT','EX','IN','JJ','JJR','JJS','LS','MD','NN','NNP','NNS','PDT','PRP','PRP$','RB','RBR','TO','UH','VB','VBD','VBG','VBN','VBP','VBZ','WDT','WP','WRB']\n",
    "    for element in elements:\n",
    "        column='first_word_'+element\n",
    "        df[column]=0\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        sents = nltk.Text(sent_tokenize(df['text'].iloc[i]))\n",
    "        first_words = first_word_type(sents)\n",
    "        for word in first_words:\n",
    "            column = 'first_word_' + str(word)\n",
    "            try:\n",
    "                df[column].iloc[i] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    del df['text']\n",
    "    if 'author' in df.columns:\n",
    "        del df['author']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatatext1 = first_word(tr1)\\ndatatext1\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datatext1 = first_word(tr1)\n",
    "datatext1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>First Two Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twofirst_words_type(sents):\n",
    "    \"\"\"Takes a list of sentences and returns a list of the 2 word types used to start each element.\"\"\"\n",
    "    res = list()\n",
    "    for sent in sents:\n",
    "        if len(sent.split()) > 1:\n",
    "            typ = nltk.pos_tag(sent.split())\n",
    "            res.append([typ[0][1],typ[1][1]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ndef twofirst_word(dataframe):\\n    \"\"\"Takes a dataframe and creates a column per word type pair with a value of 1 on the word type pair used.\"\"\"\\n    df = dataframe.copy()\\n    for i in range(len(df)):\\n        sents = nltk.Text(sent_tokenize(df[\\'text\\'].iloc[i]))\\n        twofirst_words = twofirst_words_type(sents)\\n        for twoword in twofirst_words:\\n            column = \\'first_two_\\' + str(twoword)\\n            try:\\n                df[column].iloc[i] += 1\\n            except:\\n                df[column] = 0\\n                df[column].iloc[i] = 1\\n                \\n    del df[\\'text\\']\\n    if \\'author\\' in df.columns:\\n        del df[\\'author\\']\\n        \\n    return df\\n\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "def twofirst_word(dataframe):\n",
    "    \"\"\"Takes a dataframe and creates a column per word type pair with a value of 1 on the word type pair used.\"\"\"\n",
    "    df = dataframe.copy()\n",
    "    for i in range(len(df)):\n",
    "        sents = nltk.Text(sent_tokenize(df['text'].iloc[i]))\n",
    "        twofirst_words = twofirst_words_type(sents)\n",
    "        for twoword in twofirst_words:\n",
    "            column = 'first_two_' + str(twoword)\n",
    "            try:\n",
    "                df[column].iloc[i] += 1\n",
    "            except:\n",
    "                df[column] = 0\n",
    "                df[column].iloc[i] = 1\n",
    "                \n",
    "    del df['text']\n",
    "    if 'author' in df.columns:\n",
    "        del df['author']\n",
    "        \n",
    "    return df\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datatext2 = twofirst_word(tr1)\n",
    "#datatext2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Last Word</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_word_type(sents):\n",
    "    \"\"\"Takes a list of sentences and returns a list of the word type used to end each element.\"\"\"\n",
    "    res= list()\n",
    "    for sent in sents:\n",
    "        typ = nltk.pos_tag(sent.split())\n",
    "        i = 0\n",
    "        j = 0\n",
    "        word = typ[-i][0].lower()\n",
    "        while i < len(sent.split()):\n",
    "            if j < len(word) and word[j] >= 'a' and word[j] <= 'z':\n",
    "                res.append(typ[-i][1])\n",
    "                break\n",
    "            i += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_word(dataframe):\n",
    "    \"\"\"Takes a dataframe and creates a column per word type with a value of 1 on the word type used.\"\"\"\n",
    "    df = dataframe.copy()\n",
    "    elements = ['FW','IN','JJ','NN','NNP','NNS','RB','RBS','RP','VB','VBD','VBN','VBP','VBZ']\n",
    "    for element in elements:\n",
    "        column='last_word_'+element\n",
    "        df[column]=0\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        sents = nltk.Text(sent_tokenize(df['text'].iloc[i]))\n",
    "        last_words = last_word_type(sents)\n",
    "        for word in last_words:\n",
    "            column = 'last_word_' + str(word)\n",
    "            try:\n",
    "                df[column].iloc[i] += 1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    del df['text']\n",
    "    if 'author' in df.columns:\n",
    "        del df['author']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatatext3 = last_word(tr1)\\ndatatext3\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datatext3 = last_word(tr1)\n",
    "datatext3\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Last Two Words</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def twolast_words_type(sents):\n",
    "    \"\"\"Takes a list of sentences and returns a list of the word types used to end each element.\"\"\"\n",
    "    res = list()\n",
    "    for sent in sents:\n",
    "        if len(sent.split()) > 1:\n",
    "            typ = nltk.pos_tag(sent.split())\n",
    "            res.append([typ[-2][1], typ[-1][1]])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef twolast_word(dataframe):\\n    \"\"\"Takes a dataframe and creates a column per word type pair with a value of 1 on the word type pairs used.\"\"\"\\n    df=dataframe.copy()\\n    for i in range(len(df)):\\n        sents=nltk.Text(sent_tokenize(df[\\'text\\'].iloc[i]))\\n        twolast_words = twolast_words_type(sents)\\n        for twoword in twolast_words:\\n            column=\\'last_two_\\' + str(twoword)\\n            try:\\n                df[column].iloc[i]=df[column].iloc[i]+1\\n            except:\\n                df[column]=0\\n                df[column].iloc[i]=1\\n                \\n    del df[\\'text\\']\\n    if \\'author\\' in df.columns:\\n        del df[\\'author\\']\\n        \\n    return df\\n'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def twolast_word(dataframe):\n",
    "    \"\"\"Takes a dataframe and creates a column per word type pair with a value of 1 on the word type pairs used.\"\"\"\n",
    "    df=dataframe.copy()\n",
    "    for i in range(len(df)):\n",
    "        sents=nltk.Text(sent_tokenize(df['text'].iloc[i]))\n",
    "        twolast_words = twolast_words_type(sents)\n",
    "        for twoword in twolast_words:\n",
    "            column='last_two_' + str(twoword)\n",
    "            try:\n",
    "                df[column].iloc[i]=df[column].iloc[i]+1\n",
    "            except:\n",
    "                df[column]=0\n",
    "                df[column].iloc[i]=1\n",
    "                \n",
    "    del df['text']\n",
    "    if 'author' in df.columns:\n",
    "        del df['author']\n",
    "        \n",
    "    return df\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datatext4 = twolast_word(tr1)\n",
    "#datatext4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Foreign Languages </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language_sent(sents):\n",
    "    \"\"\"Takes a list of sentences and returns a list of the languages detected for each sentence.\"\"\"\n",
    "    res = list()\n",
    "    for sent in sents:\n",
    "        try:\n",
    "            res.append(detect(sent))\n",
    "        except:\n",
    "            pass        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def language(dataframe):\n",
    "    \"\"\"Takes a dataframe and creates a column per language with a value of 1 on the languages used.\"\"\"\n",
    "    df = dataframe.copy()\n",
    "    languages=['af','ca','cy','da','de','es','et','fi','fr','hu','ind','it','nl','no','pl','pt','ro','sk','sl','so','sv','tl','tr','vi']\n",
    "    for language in languages:\n",
    "        df[language]=0\n",
    "        \n",
    "    for i in range(len(df)):\n",
    "        sents = nltk.Text(sent_tokenize(df['text'].iloc[i]))\n",
    "        n = len(sents)\n",
    "        languages = language_sent(sents)\n",
    "        for language in languages:\n",
    "            if language != 'id':\n",
    "                column = language\n",
    "                try:\n",
    "                    df[column].iloc[i] = df[column].iloc[i] + 1 / n\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                column='ind'\n",
    "                try:\n",
    "                    df[column].iloc[i] = df[column].iloc[i] + 1 / n\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    del df['text']\n",
    "    if 'author' in df.columns:\n",
    "        del df['author']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatatext5 = language(tr1)\\ndatatext5\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datatext5 = language(tr1)\n",
    "datatext5\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Emotions </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function needs to have the file \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\" in the same folder.\n",
    "Based on NRC data: 8 emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nrc_data():\n",
    "    \"\"\"Builds an emotion dictionary from the NRC emotion lexicon.\"\"\"\n",
    "    nrc = \"NRC-emotion-lexicon-wordlevel-alphabetized-v0.92.txt\"\n",
    "    count = 0\n",
    "    emotion_dict = dict()\n",
    "    with open(nrc,'r') as f:\n",
    "        all_lines = list()\n",
    "        for line in f:\n",
    "            if count < 46:\n",
    "                count += 1\n",
    "                continue\n",
    "            line = line.strip().split('\\t')\n",
    "            if int(line[2]) == 1:\n",
    "                if emotion_dict.get(line[0]):\n",
    "                    emotion_dict[line[0]].append(line[1])\n",
    "                else:\n",
    "                    emotion_dict[line[0]] = [line[1]]\n",
    "    return emotion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emotions(dataframe):\n",
    "    \"\"\"Takes a dataframe and creates a column per emotion with a count on the emotions used.\"\"\"\n",
    "    df = dataframe.copy()\n",
    "    emotions=['positive','anger','disgust','fear','negative','sadness','anticipation','joy','surprise','trust']\n",
    "    for emotion in emotions:\n",
    "        df[emotion]=0\n",
    "    \n",
    "    \n",
    "    emotion_dic = get_nrc_data()\n",
    "    for i in range(len(df)):\n",
    "        words = df['text'].iloc[i].split()\n",
    "        n = len(words)\n",
    "        for word in words:\n",
    "            if word in emotion_dic:\n",
    "                for emotion in emotion_dic[word]:\n",
    "                    column = emotion\n",
    "                    try:\n",
    "                        df[column].iloc[i] = df[column].iloc[i] + 1 / n\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "    del df['text']\n",
    "    if 'author' in df.columns:\n",
    "        del df['author']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatatext6 = emotions(tr1)\\ndatatext6\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datatext6 = emotions(tr1)\n",
    "datatext6\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Counting of words (a.k.a bag of words)</h3>\n",
    "\n",
    "Instead of word/ n-grams frequencies, we are going to use tf_idf.\n",
    "\n",
    "Some information about tf_idf: https://buhrmann.github.io/tfidf-analysis.html\n",
    "\n",
    "Here, we don't detail for each N. Instead, we'll run the tf_idf for all the n-grams possible and the we'll take the best features. Our aim is to reduce the size/dimensions of our dataset's features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_tag(var):\n",
    "    \"\"\"Transforms a string to a string of pos_tag\"\"\"\n",
    "    inpt = nltk.pos_tag(word_tokenize(var))\n",
    "    unzipped = zip(*inpt )\n",
    "    return ' '.join([*list(unzipped)[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generation of the tf_idf counting dataFrame</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counting_a(a, analysis):\n",
    "    \"\"\"\n",
    "    Generates the tf-idf counting dataframe. First argument is the n of n-gram. Analysis type is 'word', 'char',\n",
    "    token_pos', etc.\n",
    "    \"\"\"\n",
    "    df_train = tr1.copy()\n",
    "    df_test  = ts1.copy()\n",
    "    \n",
    "    #if we are counting words:\n",
    "    if analysis == \"word\" or analysis == \"char\": \n",
    "        \n",
    "        #check the CountVectorizer doc\n",
    "        #we create a Countvectorizer, called bow_transformer\n",
    "        bow_transformer = CountVectorizer(analyzer = analysis,\n",
    "                                      lowercase = True, #we don't care about place in sentence\n",
    "                                      ngram_range = (a, a),\n",
    "                                      stop_words='english')\n",
    "\n",
    "        #we use bow_transformer to fit and transform our training set\n",
    "        messages_bow = bow_transformer.fit_transform(df_train['text'])\n",
    "        \n",
    "        #we use bow_transformer to transform our test set. \n",
    "        #We do not need to train if first because the fitting would recompute the idf, we don't want that\n",
    "        messages_bow_test = bow_transformer.transform(df_test['text'])\n",
    "    \n",
    "    #if we are counting POS:    \n",
    "    elif analysis == \"token_pos\":\n",
    "        \n",
    "        #this is the punctuation we want to keep\n",
    "        punctuation = r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\.|\\,|\\;|\\:|\\$|\\(|\\)|\\--|\\&|\\``|\\'' + PRP$ + WP$\"\n",
    "        #we create a Countvectorizer, called bow_transformer\n",
    "        bow_transformer = CountVectorizer(analyzer = 'word',\n",
    "                                          lowercase = False, #we DO care about place in sentence\n",
    "                                          ngram_range = (a, a),\n",
    "                                          token_pattern =  punctuation, #we DO care about punctuation\n",
    "                                          stop_words='english')\n",
    "        \n",
    "        #we use the transform_tag function to transform the sentence in a sentence of pos tag        \n",
    "        #we use bow_transformer to fit and transform our training set\n",
    "        messages_bow = bow_transformer.fit_transform(df_train['text'].apply(transform_tag))\n",
    "        #we use bow_transformer to transform our test set\n",
    "        #We do not need to train if first because the fitting would recompute the idf, we don't want that\n",
    "        messages_bow_test = bow_transformer.transform(df_test['text'].apply(transform_tag))\n",
    "\n",
    "        \n",
    "    #this is the DataFrame Concerning the regular counting of words\n",
    "    \n",
    "    ##from regular counting to tf idf transformation coefficient\n",
    "\n",
    "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "    messages_tfidf_test = tfidf_transformer.transform(messages_bow_test)\n",
    "    \n",
    "    names = bow_transformer.get_feature_names()\n",
    "    \n",
    "    return (messages_tfidf, names, messages_tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (225, 2487)\n",
      "Amount of Non-Zero occurences:  2493\n",
      "sparsity: 0.45%\n",
      " \n",
      "Shape of Sparse Matrix Test:  (75, 2487)\n",
      "Amount of Non-Zero occurences:  3\n",
      "sparsity: 0.00%\n"
     ]
    }
   ],
   "source": [
    "#mat_word, name_word, mat_word_test = counting_a(2,'word')\n",
    "mat_word, name_word, mat_word_test = counting_a(2,'word')\n",
    "\n",
    "print ('Shape of Sparse Matrix: ', mat_word.shape)\n",
    "print ('Amount of Non-Zero occurences: ', mat_word.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * mat_word.nnz /\n",
    "                             (mat_word.shape[0] * mat_word.shape[1])))\n",
    "       \n",
    "print(' ')\n",
    "print ('Shape of Sparse Matrix Test: ', mat_word_test.shape)\n",
    "print ('Amount of Non-Zero occurences: ', mat_word_test.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * mat_word_test.nnz /\n",
    "                             (mat_word_test.shape[0] * mat_word_test.shape[1])))\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we get a matrix with <u>roughly a thousand </u>of  features. It's really heavy and we get a sparse matrix. Our goal is now to reduce the size of this matrix by getting the TOP-N features issued from the tf_idf.<br>\n",
    "<br>\n",
    "And we can create so both the matrix of training set. On which the TF_IDF is trained. <br>\n",
    "And the matrix test, which is created with no-fit on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reduction of the number of features to N</h4>\n",
    "\n",
    "The next cell will be called in all the bag of words parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    \"\"\"Gets top n tf-idf values in row and return them with their corresponding feature names.\"\"\"\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    \"\"\"Returns the top n tf-df features in a specific document (i.e. matrix row)\"\"\"\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    \"\"\"\n",
    "    Returns the top n features that on average are most important amongst documents in rows.\n",
    "    Indentified by indices in grp_ids.\n",
    "    \"\"\"\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_feats_by_class(Xtr, y, features, min_tfidf=0.1, top_n=25):\n",
    "    \"\"\"\n",
    "    Return a list of dfs, where each df holds top_n features and their mean tfidf value.\n",
    "    Calculated across documents with the same class label.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        ids = np.where(y==label)\n",
    "        feats_df = top_mean_feats(Xtr, features, ids, min_tfidf=min_tfidf, top_n=top_n)\n",
    "        feats_df.label = label\n",
    "        dfs.append(feats_df)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tfidf_classfeats_h(dfs, name = 'default'):\n",
    "    \"\"\"Plot the data frames returned by the function plot_tfidf_classfeats().\"\"\"\n",
    "    fig = plt.figure(figsize=(12, 9), facecolor=\"w\")\n",
    "    x = np.arange(len(dfs[0]))\n",
    "    for i, df in enumerate(dfs):\n",
    "        ax = fig.add_subplot(1, len(dfs), i+1)\n",
    "        ax.spines[\"top\"].set_visible(False)\n",
    "        ax.spines[\"right\"].set_visible(False)\n",
    "        ax.set_frame_on(False)\n",
    "        ax.get_xaxis().tick_bottom()\n",
    "        ax.get_yaxis().tick_left()\n",
    "        ax.set_xlabel(\"Mean Tf-Idf Score\", labelpad=16, fontsize=14)\n",
    "        ax.set_title(\"label = \" + str(df.label), fontsize=16)\n",
    "        ax.ticklabel_format(axis='x', style='sci', scilimits=(-2,2))\n",
    "        ax.barh(x, df.tfidf, align='center', color='#3F5D7D')\n",
    "        ax.set_yticks(x)\n",
    "        ax.set_ylim([-1, x[-1]+1])\n",
    "        yticks = ax.set_yticklabels(df.feature)\n",
    "        plt.subplots_adjust(bottom=0.09, right=0.97, left=0.15, top=0.95, wspace=0.52)\n",
    "    #this line is for saving as picture\n",
    "    plt.savefig(name)\n",
    "    #this line is for showing\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dimensionality reduction for bag of words (example for 2-grams)</h4>\n",
    "We reduce by taking the TOP-N per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha_word = top_feats_by_class(mat_word, tr1.author, name_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_tfidf_classfeats_h(alpha_word, 'bi_gram_word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building of bag of word and feature vectors</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# counting_a(1,'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bag_a(a, analysis, top_n = 50):\n",
    "    df_bag = tr1.copy()\n",
    "    df_bag_test = ts1.copy()\n",
    "    \n",
    "    build = counting_a(a, analysis)\n",
    "    \n",
    "    alpha = top_feats_by_class(build[0], df_bag.author, build[1], top_n = top_n)\n",
    "\n",
    "    a = list(alpha[0].feature.values)\n",
    "    b = list(alpha[1].feature.values)\n",
    "    c = list(alpha[2].feature.values)\n",
    "    bag = set(a + b + c)\n",
    "\n",
    "\n",
    "    for w in bag:\n",
    "        vec = build[0][:, build[1].index(w)].toarray()\n",
    "        df_bag[w] = vec\n",
    "\n",
    "        vec_test = build[2][:, build[1].index(w)].toarray()\n",
    "        df_bag_test[w] = vec_test\n",
    "        \n",
    "    df_bag = df_bag.drop(labels = ['text','author'], axis = 1)\n",
    "    df_bag_test = df_bag_test.drop(labels = ['text','author'], axis = 1)\n",
    "\n",
    "        \n",
    "    return df_bag, df_bag_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build_bag_a(4, 'token_pos')[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build_bag_a(2, 'word')[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build_bag_a(2, 'token_pos')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(set(list(build_bag_a(2, 'word')[1]))-set(list(build_bag_a(2, 'word')[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we get the top N-grams of words. Our problem is the depedency on the topic. We need to produce other features which are less dependant on the topic. There are sereveral possibility. Let's detail: <br>\n",
    "- Stemming<br>\n",
    "- Character Counting<br>\n",
    "- Pos_tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Counting of Character (a.k.a bag of character)</h2>\n",
    "\n",
    "Here, we count the use of some caracter, and n-grams of caracter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Generation of the tf-idf counting dataFrame</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (225, 3599)\n",
      "Amount of Non-Zero occurences:  29049\n",
      "sparsity: 3.59%\n",
      " \n",
      "Shape of Sparse Matrix Test:  (75, 3599)\n",
      "Amount of Non-Zero occurences:  9634\n",
      "sparsity: 3.57%\n"
     ]
    }
   ],
   "source": [
    "mat_char, name_char, mat_char_test = counting_a(3, 'char')\n",
    "\n",
    "print ('Shape of Sparse Matrix: ', mat_char.shape)\n",
    "print ('Amount of Non-Zero occurences: ', mat_char.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * mat_char.nnz /\n",
    "                             (mat_char.shape[0] * mat_char.shape[1])))\n",
    "print(' ')\n",
    "print ('Shape of Sparse Matrix Test: ', mat_char_test.shape)\n",
    "print ('Amount of Non-Zero occurences: ', mat_char_test.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * mat_char_test.nnz /\n",
    "                             (mat_char_test.shape[0] * mat_char_test.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Dimensionnality reduction for bag of characters example for 3 gram</h3>\n",
    "We reduce by taking the TOP-N per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha_char = top_feats_by_class( mat_char, tr1.author, name_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot_tfidf_classfeats_h(alpha_char, 'tr_gram_char')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building of bag of character and feature vectors</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build_bag_a(3, 'char')[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Counting of POS Tag (a.k.a bag of Tag)</h2>\n",
    "\n",
    "Here, we count the use of some caracter, and n-grams of caracter.<br>\n",
    "So we have, some non-topic sensitive features.<br>\n",
    "But we can produce an other type of feature based on the POS_tagging.\n",
    "\n",
    "POS tag features. \n",
    "\n",
    "We will check the occurence of the elements from the Upenn Tagset. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBP|\\PDT|\\CD|\\MD|\\SYM|\\:|\\WP|\\``|\\--|\\$|\\JJS|\\RBR|\\JJ|\\POS|\\CC|\\,|\\JJR|\\VBN|\\TO|\\NNPS|\\VBZ|\\PRP|\\RB|\\NNP|\\)|\\EX|\\.|\\VB|\\NNS|\\VBG|\\IN|\\(|\\VBD|\\WDT|\\NN|\\RBS|\\PRP$|\\FW|\\WP$|\\''|\\UH|\\WRB|\\RP|\\DT|\\LS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('tagsets')\n",
    "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "#list of all the possible tag names\n",
    "print(\"|\\\\\".join(list(tagdict)))\n",
    "\n",
    "#this is the list of the different tokens we will use.\n",
    "len(tagdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3>Generation of the tf-idf counting dataFrame</h3>\n",
    "We had to adapt the arguments passed in the CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (225, 4039)\n",
      "Amount of Non-Zero occurences:  6640\n",
      "sparsity: 0.73%\n",
      "Shape of Sparse Test Matrix:  (75, 4039)\n",
      "Amount of Non-Zero occurences:  1208\n",
      "sparsity: 0.40%\n"
     ]
    }
   ],
   "source": [
    "mat_pos, name_pos, mat_pos_test = counting_a(4, 'token_pos')\n",
    "\n",
    "print ('Shape of Sparse Matrix: ', mat_pos.shape)\n",
    "print ('Amount of Non-Zero occurences: ', mat_pos.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * mat_pos.nnz /\n",
    "                             (mat_pos.shape[0] * mat_pos.shape[1])))\n",
    "\n",
    "print ('Shape of Sparse Test Matrix: ', mat_pos_test.shape)\n",
    "print ('Amount of Non-Zero occurences: ', mat_pos_test.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * mat_pos_test.nnz /\n",
    "                             (mat_pos_test.shape[0] * mat_pos_test.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dimensionnality reduction for bag of tags Example for 2 grams</h3>\n",
    "We reduce by taking the TOP-N per author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#alpha_pos = top_feats_by_class(mat_pos, tr1.author, name_pos, top_n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot_tfidf_classfeats_h(alpha_pos, \"four_gram_tag_pos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Building of bag of tag and feature vectors</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build_bag_a(2,'token_pos')[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Positivity/Negativity</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Weighted sentiment analysis using Vader</h4>\n",
    "Vader contains a list of 7500 features weighted by how positive or negative they are</h4>\n",
    "<br>It uses these features to calculate stats on how positive, negative and neutral a passage is<br>\n",
    "<br>And combines these results to give a compound sentiment (higher = more positive) for the passage<br>\n",
    "<br>Human trained on twitter data and generally considered good for informal communication<br>\n",
    "<br>10 humans rated each feature in each tweet in context from -4 to +4</h4>\n",
    "<br>Calculates the sentiment in a sentence using word order analysis</h4>\n",
    "<br>\"marginally good\" will get a lower positive score than \"extremely good\"\n",
    "<br>Computes a \"compound\" score based on heuristics (between -1 and +1)</h4>\n",
    "<br>Includes sentiment of emoticons, punctuation, and other 'social media' lexicon elements<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vader_comparison(texts):\n",
    "    headers = ['pos','neg','neu','compound']\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    sentences = sent_tokenize(texts)\n",
    "    pos = compound = neu = neg = 0\n",
    "    num_sentences = len(sentences)\n",
    "    for sentence in sentences:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        pos += vs['pos'] / num_sentences\n",
    "        compound += vs['compound'] / num_sentences\n",
    "        neu += vs['neu'] / num_sentences\n",
    "        neg += vs['neg'] / num_sentences\n",
    "    return pos, neg, neu, compound\n",
    "\n",
    "def density_positive(var):\n",
    "    return vader_comparison(var)[0]\n",
    "\n",
    "def density_negative(var):\n",
    "    return vader_comparison(var)[1]\n",
    "\n",
    "def density_neutral(var):\n",
    "    return vader_comparison(var)[2]\n",
    "\n",
    "def density_compound(var):\n",
    "    return vader_comparison(var)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_sensi(dataframe):\n",
    "    df_sen = dataframe.copy() #change here to make sense\n",
    "    \n",
    "    df_sen[density_positive.__name__] = df_sen.text.apply(density_positive)\n",
    "    df_sen[density_negative.__name__] = df_sen.text.apply(density_negative)\n",
    "    df_sen[density_neutral.__name__] = df_sen.text.apply(density_neutral)\n",
    "    df_sen[density_compound.__name__] = df_sen.text.apply(density_compound)\n",
    "    \n",
    "    del df_sen['text']\n",
    "    if 'author' in df_sen.columns:\n",
    "        del df_sen['author']\n",
    "    return df_sen\n",
    "\n",
    "#build_sensi(ts1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndatatext7 = build_sensi(tr1)\\ndatatext7\\n'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "datatext7 = build_sensi(tr1)\n",
    "datatext7\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#see returns an error because referenced function used by datatext7 dropped the 'author' column\n",
    "\n",
    "# for c in datatext7.columns[3:]:\n",
    "#     plt.style.use('seaborn')\n",
    "#     sns.boxplot(x = 'author', y = c, data = datatext7)\n",
    "#     plt.title('Sensi {}'.format(c))\n",
    "#     plt.savefig('Sensi {}'.format(c))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h2>Fusion of the bunch of features.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#we build here the 2 feature datasets (one for TR1, one for TS1)\n",
    "#should be adapted when we'll add features\n",
    "\n",
    "def build_bunch_tr1(dataframe):\n",
    "    list_df_tr = [build_meta2(dataframe),\n",
    "                  build_meta1(dataframe),\n",
    "                  build_sensi(dataframe),\n",
    "                  build_bag_a(1, 'word')[0],\n",
    "                  build_bag_a(2, 'word')[0],\n",
    "                  build_bag_a(3, 'word')[0],\n",
    "                  build_bag_a(1, 'char')[0],\n",
    "                  build_bag_a(2, 'char')[0],\n",
    "                  build_bag_a(3, 'char')[0],\n",
    "                  build_bag_a(4, 'char')[0],\n",
    "                  build_bag_a(5, 'char')[0],\n",
    "                  build_bag_a(6, 'char')[0],\n",
    "                  build_bag_a(7, 'char')[0],\n",
    "                  build_bag_a(1, 'token_pos')[0],\n",
    "                  build_bag_a(2, 'token_pos')[0],\n",
    "                  build_bag_a(3, 'token_pos')[0],\n",
    "                  build_bag_a(4, 'token_pos')[0],\n",
    "                  build_bag_a(5, 'token_pos')[0],\n",
    "                  build_bag_a(6, 'token_pos')[0],\n",
    "                  first_word(dataframe),\n",
    "#                   twofirst_word(dataframe),\n",
    "                  last_word(dataframe),\n",
    "#                   twolast_word(dataframe),\n",
    "                  language(dataframe),\n",
    "                  emotions(dataframe)\n",
    "              ]\n",
    "    bunch = pd.merge(list_df_tr[0], list_df_tr[1])\n",
    "    \n",
    "    for i in range(2, len(list_df_tr)):\n",
    "        alpha = bunch\n",
    "        bunch = pd.merge(alpha, list_df_tr[i], on = 'id')\n",
    "    \n",
    "    return bunch\n",
    "\n",
    "#df_feat_tr1 = build_bunch_tr1(tr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bunch_ts1(dataframe):\n",
    "    list_df_ts = [build_meta2(dataframe),\n",
    "                  build_meta1(dataframe),\n",
    "                  build_sensi(dataframe),\n",
    "                  build_bag_a(1,'word')[1],\n",
    "                  build_bag_a(2,'word')[1],\n",
    "                  build_bag_a(3,'word')[1],\n",
    "               \n",
    "                  build_bag_a(1,'char')[1],\n",
    "                  build_bag_a(2,'char')[1],\n",
    "                  build_bag_a(3,'char')[1],\n",
    "                  build_bag_a(4,'char')[1],\n",
    "                  build_bag_a(5,'char')[1],\n",
    "                  build_bag_a(6,'char')[1],\n",
    "                  build_bag_a(7,'char')[1],\n",
    "               \n",
    "                  build_bag_a(1, 'token_pos')[1],\n",
    "                  build_bag_a(2, 'token_pos')[1],\n",
    "                  build_bag_a(3, 'token_pos')[1],\n",
    "                  build_bag_a(4, 'token_pos')[1],\n",
    "                  build_bag_a(5, 'token_pos')[1],\n",
    "                  build_bag_a(6, 'token_pos')[1],\n",
    "                  first_word(dataframe),\n",
    "#                   twofirst_word(dataframe),\n",
    "                  last_word(dataframe),\n",
    "#                   twolast_word(dataframe),\n",
    "                  language(dataframe),\n",
    "                  emotions(dataframe)\n",
    "                 ]\n",
    "\n",
    "    bunch = pd.merge(list_df_ts[0], list_df_ts[1])\n",
    "    \n",
    "    for i in range(2, len(list_df_ts)):\n",
    "        print(bunch.shape)\n",
    "        bunch = pd.merge(bunch, list_df_ts[i], on = 'id')\n",
    "    \n",
    "    return bunch\n",
    "#df_feat_ts1 = build_bunch_ts1(ts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print ('Shape of df_feat_tr1 Matrix: ', df_feat_tr1.shape)\n",
    "# print ('Amount of Non-Zero occurences: ', np.count_nonzero(df_feat_tr1.values))\n",
    "# print ('sparsity: %.2f%%' % (100.0 * np.count_nonzero(df_feat_tr1.values) /\n",
    "#                                  (df_feat_tr1.shape[0] * df_feat_tr1.shape[1])))\n",
    "# print('')\n",
    "\n",
    "# print ('Shape of df_feat_ts1 Matrix: ', df_feat_ts1.shape)\n",
    "# print ('Amount of Non-Zero occurences: ', np.count_nonzero(df_feat_ts1.values))\n",
    "# print ('sparsity: %.2f%%' % (100.0 * np.count_nonzero(df_feat_ts1.values) /\n",
    "#                                  (df_feat_ts1.shape[0] * df_feat_ts1.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Quantitative parameters transformation</h2>\n",
    "Quantitative parameters were transferred into a numerical vector with min-max normalization\n",
    "from 0 to 1. <br>\n",
    "<br>\n",
    "It is necessary to have normalized vectors before training our dataset to avoid a disequilibrium among the coefficients.\n",
    "\n",
    "http://blog.josephmisiti.com/help-commands-for-doing-machine-learning-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_normalization(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in list(df)[3:]:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        if max_value != min_value:\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "#build_normalization(df_feat_ts1).head()\n",
    "\n",
    "#df_feat_ts1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we have the normalized features matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Prediction: Selection of best set of feature selection technique and prediction model </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Load and prepare data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 25)\n",
      "(75, 29)\n",
      "(75, 170)\n",
      "(75, 320)\n",
      "(75, 470)\n",
      "(75, 506)\n",
      "(75, 584)\n",
      "(75, 714)\n",
      "(75, 859)\n",
      "(75, 1008)\n",
      "(75, 1158)\n",
      "(75, 1308)\n",
      "(75, 1346)\n",
      "(75, 1429)\n",
      "(75, 1539)\n",
      "(75, 1663)\n",
      "(75, 1797)\n",
      "(75, 1942)\n",
      "(75, 1971)\n",
      "(75, 1985)\n",
      "(75, 2009)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "names = author_list\n",
    "dataframe_train = build_normalization(build_bunch_tr1(tr1))\n",
    "dataframe_train.to_csv('dataframe_train')\n",
    "array = dataframe_train.values\n",
    "X_train = array[:,3:]\n",
    "Y_train = array[:,2]\n",
    "\n",
    "names = author_list\n",
    "dataframe_test = build_normalization(build_bunch_ts1(ts1))\n",
    "dataframe_test.to_csv('dataframe_test')\n",
    "array = dataframe_test.values\n",
    "X_test = array[:,3:]\n",
    "Y_test = array[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(np.shape(X_train))\\nprint(np.shape(X_test))\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Selection</h2><br>\n",
    "See:http://scikit-learn.org/stable/modules/feature_selection.html <br><br>\n",
    "Feature selection is a process where you automatically select those features in your data that contribute most to the prediction variable or output in which you are interested.<br>\n",
    "<br>\n",
    "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression.<br>\n",
    "<br>\n",
    "Three benefits of performing feature selection before modeling your data are:<br>\n",
    "<br>\n",
    "- <b>Reduces Overfitting:</b> Less redundant data means less opportunity to make decisions based on noise.<br>\n",
    "    <br>\n",
    "- <b>Improves Accuracy:</b> Less misleading data means modeling accuracy improves.<br>\n",
    "    <br>\n",
    "- <b>Reduces Training Time:</b> Less data means that algorithms train faster.\n",
    "<br><br>I will not follow the paper here but rather I'll follow the following website: <br>\n",
    "\n",
    "https://machinelearningmastery.com/feature-selection-machine-learning-python/ <br>\n",
    "see also: https://www.analyticsvidhya.com/blog/2016/12/introduction-to-feature-selection-methods-with-an-example-or-how-to-select-the-right-variables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, here we will try a bunch of different methods:<br>\n",
    "- Univariate feature selection\n",
    "- Recursive feature elimination\n",
    "- L1-based feature selection\n",
    "- Tree-based feature selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Number of selected features</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Current number of features</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2016 features in total.\n"
     ]
    }
   ],
   "source": [
    "print('We have ' + str(np.shape(X_train)[1]) + ' features in total.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reduction of  number of feaures</h4>\n",
    "The common possibilities are 10,20, quarter and half of total number of samples. <br>\n",
    "<br>\n",
    "For now, we only explore with quarter, tbd for the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We want to test our models with [10, 20, 504, 1008] features extracted from the 2016 previous features\n"
     ]
    }
   ],
   "source": [
    "list_N = [10, 20, int(np.shape(X_train)[1]/4), int(np.shape(X_train)[1]/2)]\n",
    "\n",
    "print('We want to test our models with ' + str(list_N) + ' features extracted from the ' + str(np.shape(X_train)[1]) + ' previous features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Univariate feature selection</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sel_univ(N):\n",
    "    return SelectKBest(chi2, k=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Recursive feature elimination</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sel_rec(N):\n",
    "    model_rec = LogisticRegression()\n",
    "    return RFE(model_rec, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Principal Component Analysis</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sel_pca(N):\n",
    "    return PCA(n_components=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_selec(N):\n",
    "    selectioners = []  \n",
    "    selectioners.append(('S_UNIV_{}'.format(N), sel_univ(N)))\n",
    "    #selectioners.append(('S_REC_{}'.format(N), sel_rec(N)))\n",
    "    #selectioners.append(('S_PCA_{}'.format(N), sel_pca(N)))\n",
    "    return selectioners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predictive Models</h2><br>\n",
    "So here we will try this bunch of feature models:\n",
    "\n",
    "- LogisticRegression\n",
    "- LinearDiscriminantAnalysis\n",
    "- KNeighborsClassifier\n",
    "- DecisionTreeClassifier\n",
    "- GaussianNB\n",
    "- SVC\n",
    "- GradientBoostingClassifier\n",
    "- AdaBoostClassifier\n",
    "- ExtraTreesClassifier\n",
    "- RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_models(N):\n",
    "    models = []\n",
    "    models.append(('LR', LogisticRegression()))\n",
    "    #models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('CART', DecisionTreeClassifier()))\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    #models.append(('SVM', SVC()))\n",
    "    models.append(('GBC', GradientBoostingClassifier()))\n",
    "    models.append(('ABC', AdaBoostClassifier()))\n",
    "    models.append(('ETC', ExtraTreesClassifier()))\n",
    "    models.append(('RFC', RandomForestClassifier()))\n",
    "    models.append(('MultiNB', MultinomialNB(alpha=0.03)))\n",
    "    models.append(('Calibrated MultiNB', CalibratedClassifierCV( MultinomialNB(alpha=0.03), method='isotonic')))\n",
    "    models.append(('Calibrated BernoulliNB', CalibratedClassifierCV( BernoulliNB(alpha=0.03), method='isotonic')))\n",
    "    models.append(('Calibrated Huber', CalibratedClassifierCV(SGDClassifier(loss='modified_huber', alpha=1e-4, max_iter=10000, tol=1e-4), method='sigmoid')))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Pipeline</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves two purposes here:<br>\n",
    "- Convenience and Encapsulation<br>\n",
    "        You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
    "- Joint parameter selection<br>\n",
    "        You can grid search over parameters of all estimators in the pipeline at once.\n",
    "- Safety<br>\n",
    "        Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors.\n",
    "All estimators in a pipeline, except the last one, must be transformers (i.e. must have a transform method). The last estimator may be any type (transformer, classifier, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_pipes(N):\n",
    "    pipes = []\n",
    "    for sel in build_selec(N):\n",
    "        for mod in build_models(N):\n",
    "            pipes.append([sel, mod])\n",
    "    return pipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compare set of selection and predictive models</h2>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here, we do ten times :<br>\n",
    "- First we train over 9/10 of the training set (TR1)\n",
    "- We test over the 1/10 remaining of the training set (TR1)<br>\n",
    "<br>\n",
    "But here we have a problem. Actually, the metric we need to mesure the models is 'neg_log_loss', because it is the one used by Kaggle. But it doesn't work and we don't know why. So, the metric used is accuracy. <br>\n",
    "<br>\n",
    "Then, we will take the 10 best models:<br>\n",
    "- We train over the whole train set(TR1)\n",
    "- We test over the whole test set (TS1)\n",
    "- we mesure the best with the neg_log_loss metric (here it's working)<br>\n",
    "Here the goal is to select the best with the Kaggle metric, but also we want to check if there is or not overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    # boxplot algorithm comparison\\n    fig = plt.figure()\\n    fig.suptitle('Algorithm Comparison when N = {}'.format(n))\\n    ax = fig.add_subplot(111)\\n    plt.boxplot(results_plot)\\n    ax.set_xticklabels(names_model, rotation='vertical')\\n    plt.show()\\n    results_plot = []\\n    \\n\""
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_N(n):\n",
    "    print('Go N')\n",
    "    \n",
    "    pipes = build_pipes(n)\n",
    "    \n",
    "    # evaluate each model in turn\n",
    "    results = []\n",
    "    names_model = []\n",
    "    results_mean_var = []\n",
    "    results_plot = []\n",
    "    seed = 7\n",
    "    count = 0\n",
    "\n",
    "    for feat, model in pipes:\n",
    "        intermediate_time = datetime.now()\n",
    "        count +=1\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "        pipeline = Pipeline([feat, model])\n",
    "        #scorer = make_scorer((metrics.log_loss), labels = [0, 1 , 2])\n",
    "        scorer = 'neg_log_loss'\n",
    "        cv_results = model_selection.cross_val_score(pipeline,\n",
    "                                                     X_train,\n",
    "                                                     Y_train,\n",
    "                                                     cv=kfold,\n",
    "                                                     scoring = scorer)\n",
    "        results.append(cv_results)\n",
    "        results_mean_var.append((feat[0] + ' ' + model[0], cv_results.mean(), cv_results.var(), cv_results.mean()-0.5*cv_results.std()))\n",
    "        results_plot.append(cv_results)\n",
    "        names_model.append(feat[0] + ' ' + model[0])\n",
    "        msg = \"%s: Mean=%f Stand Dev=(%f)\" % ('Selector: ' + feat[0] + ' Predictive model: ' + model[0], cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "        print('Running time: {}'.format(datetime.now() - start_time))\n",
    "        print('Intermediate time: {}'.format(datetime.now() - intermediate_time))\n",
    "    return (results, results_mean_var)\n",
    "\n",
    "'''\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison when N = {}'.format(n))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results_plot)\n",
    "    ax.set_xticklabels(names_model, rotation='vertical')\n",
    "    plt.show()\n",
    "    results_plot = []\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#eval_N(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go N\n",
      "Go N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: LR: Mean=-1.067483 Stand Dev=(0.063293)Selector: S_UNIV_20 Predictive model: LR: Mean=-1.049298 Stand Dev=(0.076022)\n",
      "Running time: 0:04:42.991329\n",
      "Intermediate time: 0:00:03.351672\n",
      "\n",
      "Running time: 0:04:42.992738\n",
      "Intermediate time: 0:00:03.353777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: KNN: Mean=-6.818496 Stand Dev=(3.006279)Selector: S_UNIV_10 Predictive model: KNN: Mean=-5.127821 Stand Dev=(3.651652)\n",
      "\n",
      "Running time: 0:04:46.348525\n",
      "Intermediate time: 0:00:03.357169\n",
      "Running time: 0:04:46.349134\n",
      "Intermediate time: 0:00:03.356392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n",
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: CART: Mean=-7.025729 Stand Dev=(2.608515)\n",
      "Running time: 0:04:49.851403\n",
      "Intermediate time: 0:00:03.502254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: CART: Mean=-11.794724 Stand Dev=(4.079733)\n",
      "Running time: 0:04:50.581451\n",
      "Intermediate time: 0:00:04.232915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: NB: Mean=-12.376618 Stand Dev=(5.934728)\n",
      "Running time: 0:04:53.139303\n",
      "Intermediate time: 0:00:03.287880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: NB: Mean=-10.209300 Stand Dev=(4.723355)\n",
      "Running time: 0:04:53.753058\n",
      "Intermediate time: 0:00:03.171118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: GBC: Mean=-1.365982 Stand Dev=(0.234530)\n",
      "Running time: 0:05:00.847142\n",
      "Intermediate time: 0:00:07.707811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: GBC: Mean=-1.273609 Stand Dev=(0.220408)\n",
      "Running time: 0:05:03.162352\n",
      "Intermediate time: 0:00:09.409603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: ABC: Mean=-1.106606 Stand Dev=(0.092147)\n",
      "Running time: 0:05:04.061187\n",
      "Intermediate time: 0:00:03.214338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: ETC: Mean=-4.399057 Stand Dev=(2.246404)\n",
      "Running time: 0:05:07.169458\n",
      "Intermediate time: 0:00:03.107914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: RFC: Mean=-3.253775 Stand Dev=(1.837380)\n",
      "Running time: 0:05:10.371445\n",
      "Intermediate time: 0:00:03.201929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: ABC: Mean=-1.099791 Stand Dev=(0.136554)\n",
      "Running time: 0:05:10.748573\n",
      "Intermediate time: 0:00:07.586869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: MultiNB: Mean=-1.167208 Stand Dev=(0.151254)\n",
      "Running time: 0:05:13.240168\n",
      "Intermediate time: 0:00:02.868683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: ETC: Mean=-4.673518 Stand Dev=(2.381875)\n",
      "Running time: 0:05:15.709182\n",
      "Intermediate time: 0:00:04.951351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: Calibrated MultiNB: Mean=-2.371338 Stand Dev=(1.775093)\n",
      "Running time: 0:05:17.137429\n",
      "Intermediate time: 0:00:03.897248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: RFC: Mean=-4.302593 Stand Dev=(1.984613)\n",
      "Running time: 0:05:19.506045\n",
      "Intermediate time: 0:00:03.796642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: Calibrated BernoulliNB: Mean=-2.550791 Stand Dev=(1.833338)\n",
      "Running time: 0:05:21.214718\n",
      "Intermediate time: 0:00:04.077754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: MultiNB: Mean=-1.303190 Stand Dev=(0.343361)\n",
      "Running time: 0:05:22.475965\n",
      "Intermediate time: 0:00:02.969836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_10 Predictive model: Calibrated Huber: Mean=-1.083015 Stand Dev=(0.062872)\n",
      "Running time: 0:05:25.688338\n",
      "Intermediate time: 0:00:04.473049\n",
      "Selector: S_UNIV_20 Predictive model: Calibrated MultiNB: Mean=-2.406590 Stand Dev=(2.132493)\n",
      "Running time: 0:05:26.168945\n",
      "Intermediate time: 0:00:03.686472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: Calibrated BernoulliNB: Mean=-1.985829 Stand Dev=(1.291961)\n",
      "Running time: 0:05:28.348575\n",
      "Intermediate time: 0:00:02.179132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selector: S_UNIV_20 Predictive model: Calibrated Huber: Mean=-1.089485 Stand Dev=(0.156705)\n",
      "Running time: 0:05:30.668581\n",
      "Intermediate time: 0:00:02.320006\n"
     ]
    }
   ],
   "source": [
    "pool = ThreadPool() \n",
    "training_results = pool.map(eval_N, list_N[:2])\n",
    "# x = pool.map_async( eval_N, list_N[0:2] )\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_results[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Selection of selection and predictive models</h2>\n",
    "<br> We take the three best estimators in mean. These will be tested other the 'TS1' test dataset. <br>\n",
    "Really not sure about me for the criterion. Because, the variance is important too. We should think about it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def get_and_select_results_mean_var():\n",
    "    list_res = [] #total list of results\n",
    "    selection = [] #top ten in term of average \n",
    "                   #subject to be in the criterion in term of mean\n",
    "    criterion = 0.1 #we reject if the mean is greater than 5%\n",
    "    \n",
    "    \n",
    "    for i in range(len(training_results)):\n",
    "        list_res.extend(training_results[i][1])\n",
    "        \n",
    "    list_res.sort(key=lambda tup: tup[3], reverse = True)\n",
    "    \n",
    "    selection = list_res[:10]\n",
    "\n",
    "    return selection\n",
    "\n",
    "selected_feat_model = get_and_select_results_mean_var()\n",
    "print(len(selected_feat_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Testing over the Testing dataset</h1> <br>\n",
    "Now, we have to test the top-10 models over the remaining training set. Our aim is to see how are they are behaviouring over an un-known dataset and select the best. We will also, and it's the most import ensure there is no overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>List of selected</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_pipes = []\n",
    "#print(build_pipes(10)[1][0][0])\n",
    "#print(selected_feat_model[2])\n",
    "for j in range(len(selected_feat_model)):\n",
    "    for n in list_N[:2]:    \n",
    "        for i in range(len(build_pipes(n))):\n",
    "            f = build_pipes(n)[i][0][0] + ' ' + build_pipes(n)[i][1][0]\n",
    "            if f == selected_feat_model[j][0]:\n",
    "                best_pipes.append((f, build_pipes(n)[i]))\n",
    "#print(len(best_pipes))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion Matrix</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclass_names = author_list\\n\\n\\n\\n\\ndef plot_confusion_matrix(cm, classes,\\n                          normalize=False,\\n                          title=\\'Confusion matrix\\',\\n                          cmap=plt.cm.Blues):\\n    \"\"\"\\n    This function prints and plots the confusion matrix.\\n    Normalization can be applied by setting `normalize=True`.\\n    \"\"\"\\n    if normalize:\\n        cm = cm.astype(\\'float\\') / cm.sum(axis=1)[:, np.newaxis]\\n        print(\"Normalized confusion matrix\")\\n    else:\\n        print(\\'Confusion matrix, without normalization\\')\\n\\n    print(cm)\\n\\n    plt.imshow(cm, interpolation=\\'nearest\\', cmap=cmap)\\n    plt.title(title)\\n    plt.colorbar()\\n    tick_marks = np.arange(len(classes))\\n    plt.xticks(tick_marks, classes, rotation=45)\\n    plt.yticks(tick_marks, classes)\\n\\n    fmt = \\'.2f\\' if normalize else \\'d\\'\\n    thresh = cm.max() / 2.\\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\\n        plt.text(j, i, format(cm[i, j], fmt),\\n                 horizontalalignment=\"center\",\\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\\n\\n    plt.tight_layout()\\n    plt.ylabel(\\'True label\\')\\n    plt.xlabel(\\'Predicted label\\')\\n\\n'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import some data to play with\n",
    "'''\n",
    "class_names = author_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef final_plot_confusion(Y_test, Y_pred):\\n\\n    cm = confusion_matrix(Y_test, Y_pred)\\n\\n    # Plot non-normalized confusion matrix\\n    plt.figure()\\n    plot_confusion_matrix(cm, classes=class_names,\\n                          title='Confusion matrix, without normalization')\\n\\n    # Plot normalized confusion matrix\\n    plt.figure()\\n    plot_confusion_matrix(cm, classes=class_names, normalize=True,\\n                          title='Normalized confusion matrix')\\n\\n    plt.show()\\n\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def final_plot_confusion(Y_test, Y_pred):\n",
    "\n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=class_names,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "\n",
    "    # Plot normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm, classes=class_names, normalize=True,\n",
    "                          title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test over Top Pipeline</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss_list = []\n",
    "for i in range(len(best_pipes)):\n",
    "    name = best_pipes[i][0]\n",
    "    pipeline = Pipeline([best_pipes[i][1][0], best_pipes[i][1][1]])\n",
    "    pipeline.fit(X_train, Y_train)\n",
    "    Y_pred = pipeline.predict(X_test)\n",
    "    y_prob_output = pipeline.predict_proba(X_test) #this is what we send to kaggle.\n",
    "    result = log_loss(Y_test, y_prob_output)\n",
    "    log_loss_list.append((name, result, pipeline))\n",
    "\n",
    "    \n",
    "log_loss_list.sort(key=lambda tup: tup[1], reverse = False)\n",
    "#log_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprint('The best combination Number, Processing, Model is ' \\n      + winner[0]\\n     + ' with a log_loss score of '\\n     + str(winner[1]))\\n     \\n\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner = log_loss_list[0]\n",
    "'''\n",
    "print('The best combination Number, Processing, Model is ' \n",
    "      + winner[0]\n",
    "     + ' with a log_loss score of '\n",
    "     + str(winner[1]))\n",
    "     \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open('selectedModel.txt','w') \n",
    " \n",
    "file.write('The best combination Number, Processing, Model is '\n",
    "           + winner[0]\n",
    "           + ' with a log_loss score of '\n",
    "           + str(winner[1]))\n",
    "\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Confusion Matrix</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npipeline = winner[2]\\npipeline.fit(X_train, Y_train)\\nY_pred = pipeline.predict(X_test)\\ny_prob_output = pipeline.predict_proba(X_test)  \\nfinal_plot_confusion(Y_test, Y_pred) \\n\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pipeline = winner[2]\n",
    "pipeline.fit(X_train, Y_train)\n",
    "Y_pred = pipeline.predict(X_test)\n",
    "y_prob_output = pipeline.predict_proba(X_test)  \n",
    "final_plot_confusion(Y_test, Y_pred) \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Submission to Kaggle</h2>\n",
    "First, we must adapt the features building functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading Test Set</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading of test dataset\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "test.text= test.text.astype(str)\n",
    "\n",
    "test = test[0:30] #for coding \n",
    "#construction of the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 2 columns):\n",
      "id      30 non-null object\n",
      "text    30 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 560.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Adapting building functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this function works for n-grams of characters, pos tokens or words\n",
    "\n",
    "#first argument is the n in n-gram\n",
    "#analysis type is 'word', 'char', token_pos', ...\n",
    "\n",
    "def counting_a_final(a, analysis):\n",
    "    \n",
    "    df_train = train.copy()\n",
    "    df_test  = test.copy()\n",
    "    \n",
    "    #if we are counting words:\n",
    "    if analysis == \"word\" or analysis == \"char\": \n",
    "        \n",
    "        #check the CountVectorizer doc\n",
    "        #we create a Countvectorizer, called bow_transformer\n",
    "        bow_transformer = CountVectorizer(analyzer = analysis,\n",
    "                                      lowercase = True, #we don't care about place in sentence\n",
    "                                      ngram_range = (a, a),\n",
    "                                      stop_words='english')\n",
    "\n",
    "        #we use bow_transformer to fit and transform our training set\n",
    "        messages_bow = bow_transformer.fit_transform(df_train['text'])\n",
    "        \n",
    "        #we use bow_transformer to transform our test set. \n",
    "        #We do not need to train if first because the fitting would recompute the idf, we don't want that\n",
    "        messages_bow_test = bow_transformer.transform(df_test['text'])\n",
    "    \n",
    "    #if we are counting POS:    \n",
    "    elif analysis == \"token_pos\":\n",
    "        \n",
    "        #this is the punctuation we want to keep\n",
    "        punctuation = r\"(?u)\\b\\w\\w+\\b|!|\\?|\\\"|\\'|\\.|\\,|\\;|\\:|\\$|\\(|\\)|\\--|\\&|\\``|\\'' + PRP$ + WP$\"\n",
    "        #we create a Countvectorizer, called bow_transformer\n",
    "        bow_transformer = CountVectorizer(analyzer = 'word',\n",
    "                                          lowercase = False, #we DO care about place in sentence\n",
    "                                          ngram_range = (a, a),\n",
    "                                          token_pattern =  punctuation, #we DO care about punctuation\n",
    "                                          stop_words='english')\n",
    "        \n",
    "        #we use the transform_tag function to transform the sentence in a sentence of pos tag        \n",
    "        #we use bow_transformer to fit and transform our training set\n",
    "        messages_bow = bow_transformer.fit_transform(df_train['text'].apply(transform_tag))\n",
    "        #we use bow_transformer to transform our test set\n",
    "        #We do not need to train if first because the fitting would recompute the idf, we don't want that\n",
    "        messages_bow_test = bow_transformer.transform(df_test['text'].apply(transform_tag))\n",
    "\n",
    "        \n",
    "    #this is the DataFrame Concerning the regular counting of words\n",
    "    \n",
    "    ##What does this do?\n",
    "    \"\"\"\n",
    "    messages_tfidf = TfidfTransformer().fit_transform(messages_bow)\n",
    "    messages_tfidf_test = TfidfTransformer().transform(messages_bow_test)\n",
    "    names = bow_transformer.get_feature_names()\n",
    "    \n",
    "    \"\"\"\n",
    "    tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "    messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "    messages_tfidf_test = tfidf_transformer.transform(messages_bow_test)\n",
    "    \n",
    "    names = bow_transformer.get_feature_names()\n",
    "     \n",
    "    \n",
    "    \n",
    "    \n",
    "    return (messages_tfidf, names, messages_tfidf_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bag_a_final(a,  analysis, top_n = 50):\n",
    "    df_bag = train.copy()\n",
    "    df_bag_test = test.copy()\n",
    "    \n",
    "    build = counting_a_final(a, analysis)\n",
    "    \n",
    "    alpha = top_feats_by_class(build[0], df_bag.author, build[1], top_n = top_n)\n",
    "\n",
    "    a = list(alpha[0].feature.values)\n",
    "    b = list(alpha[1].feature.values)\n",
    "    c = list(alpha[2].feature.values)\n",
    "    bag = set(a + b + c)\n",
    "\n",
    "\n",
    "    for w in bag:\n",
    "        vec = build[0][:, build[1].index(w)].toarray()\n",
    "        df_bag[w] = vec\n",
    "\n",
    "        vec_test = build[2][:, build[1].index(w)].toarray()\n",
    "        df_bag_test[w] = vec_test\n",
    "        \n",
    "    df_bag = df_bag.drop(labels = ['text','author'], axis = 1)\n",
    "    df_bag_test = df_bag_test.drop(labels = ['text'], axis = 1)\n",
    "\n",
    "        \n",
    "    return df_bag, df_bag_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we build here the 2 feature datasets (one for train, one for test)\n",
    "#should be adapted when we'll add features\n",
    "\n",
    "def build_bunch_train(dataframe):\n",
    "    list_df_tr = [build_meta2(dataframe),\n",
    "                  build_meta1(dataframe),\n",
    "                  build_sensi(dataframe),\n",
    "                  build_bag_a_final(1,'word')[0],\n",
    "                  build_bag_a_final(2,'word')[0],\n",
    "                  build_bag_a_final(3,'word')[0],\n",
    "                  build_bag_a_final(1,'char')[0],\n",
    "                  build_bag_a_final(2,'char')[0],\n",
    "                  build_bag_a_final(3,'char')[0],\n",
    "                  build_bag_a_final(4,'char')[0],\n",
    "                  build_bag_a_final(5,'char')[0],\n",
    "                  build_bag_a_final(6,'char')[0],\n",
    "                  build_bag_a_final(7,'char')[0],\n",
    "                  build_bag_a_final(1, 'token_pos')[0],\n",
    "                  build_bag_a_final(2, 'token_pos')[0],\n",
    "                  build_bag_a_final(3, 'token_pos')[0],\n",
    "                  build_bag_a_final(4, 'token_pos')[0],\n",
    "                  build_bag_a_final(5, 'token_pos')[0],\n",
    "                  build_bag_a_final(6, 'token_pos')[0],\n",
    "                  first_word(dataframe),\n",
    "#                   twofirst_word(dataframe),\n",
    "                  last_word(dataframe),\n",
    "#                   twolast_word(dataframe),\n",
    "                  language(dataframe),\n",
    "                  emotions(dataframe)\n",
    "              ]\n",
    "    bunch = pd.merge(list_df_tr[0], list_df_tr[1])\n",
    "    \n",
    "    for i in range(2, len(list_df_tr)):\n",
    "        alpha = bunch\n",
    "        bunch = pd.merge(alpha, list_df_tr[i], on = 'id')\n",
    "    \n",
    "    return bunch\n",
    "\n",
    "#build_bunch_train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_bunch_test(dataframe):\n",
    "    list_df_ts = [build_meta2(dataframe),\n",
    "                  build_meta1(dataframe),\n",
    "                  build_sensi(dataframe),\n",
    "                  build_bag_a_final(1,'word')[1],\n",
    "                  build_bag_a_final(2,'word')[1],\n",
    "                  build_bag_a_final(3,'word')[1],\n",
    "\n",
    "                  build_bag_a_final(1,'char')[1],\n",
    "                  build_bag_a_final(2,'char')[1],\n",
    "                  build_bag_a_final(3,'char')[1],\n",
    "                  build_bag_a_final(4,'char')[1],\n",
    "                  build_bag_a_final(5,'char')[1],\n",
    "                  build_bag_a_final(6,'char')[1],\n",
    "                  build_bag_a_final(7,'char')[1],\n",
    "               \n",
    "                  build_bag_a_final(1, 'token_pos')[1],\n",
    "                  build_bag_a_final(2, 'token_pos')[1],\n",
    "                  build_bag_a_final(3, 'token_pos')[1],\n",
    "                  build_bag_a_final(4, 'token_pos')[1],\n",
    "                  build_bag_a_final(5, 'token_pos')[1],\n",
    "                  build_bag_a_final(6, 'token_pos')[1],\n",
    "                  first_word(dataframe),\n",
    "#                   twofirst_word(dataframe),\n",
    "                  last_word(dataframe),\n",
    "#                   twolast_word(dataframe),\n",
    "                  language(dataframe),\n",
    "                  emotions(dataframe)\n",
    "                 ]\n",
    "\n",
    "\n",
    "    bunch = pd.merge(list_df_ts[0], list_df_ts[1])\n",
    "    \n",
    "    for i in range(2, len(list_df_ts)):\n",
    "        bunch = pd.merge(bunch, list_df_ts[i], on = 'id')\n",
    "    \n",
    "    return bunch\n",
    "\n",
    "#build_bunch_test(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training over all the Training Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pcamizrahi/.local/lib/python3.5/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "\n",
    "names = author_list\n",
    "dataframe_train = build_normalization(build_bunch_train(train))\n",
    "dataframe_train.to_csv('final_dataframe_train')\n",
    "array = dataframe_train.values\n",
    "X_train = array[:,3:]\n",
    "Y_train = array[:,2]\n",
    "\n",
    "names = author_list\n",
    "dataframe_test = build_normalization(build_bunch_test(test))\n",
    "dataframe_test.to_csv('final_dataframe_train')\n",
    "array = dataframe_test.values\n",
    "X_test = array[:,2:]\n",
    "Y_test = array[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1996)\n",
      "(30, 1996)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('S_UNIV_20', SelectKBest(k=20, score_func=<function chi2 at 0x7fad111459d8>)), ('LR', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "pipeline = winner[2]\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generating the probabilities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = pipeline.predict(X_test)\n",
    "y_prob_output = pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07016277  0.2286919   0.70114533]\n",
      " [ 0.41312164  0.38955334  0.19732502]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.38746995  0.05232463  0.56020541]\n",
      " [ 0.15485381  0.30043548  0.54471071]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.19668948  0.14040288  0.66290764]\n",
      " [ 0.76606991  0.18388141  0.05004868]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.31332778  0.39196388  0.29470833]\n",
      " [ 0.24588079  0.25707284  0.49704636]\n",
      " [ 0.1315182   0.03025757  0.83822423]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.3401268   0.38455943  0.27531377]\n",
      " [ 0.12269896  0.16283866  0.71446238]\n",
      " [ 0.14960752  0.20489039  0.6455021 ]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.27637742  0.30650757  0.41711501]\n",
      " [ 0.88892319  0.04638678  0.06469003]\n",
      " [ 0.44590879  0.29157564  0.26251557]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.83934263  0.1107613   0.04989607]\n",
      " [ 0.08725837  0.15330004  0.7594416 ]\n",
      " [ 0.45970786  0.38833289  0.15195924]\n",
      " [ 0.69129784  0.24498477  0.06371738]\n",
      " [ 0.06128828  0.06468466  0.87402706]\n",
      " [ 0.12787088  0.0453952   0.82673392]]\n"
     ]
    }
   ],
   "source": [
    "print(y_prob_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CSV File</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.07016277,  0.41312164,  0.45970786,  0.38746995,  0.15485381,\n",
       "        0.45970786,  0.45970786,  0.19668948,  0.76606991,  0.45970786,\n",
       "        0.31332778,  0.24588079,  0.1315182 ,  0.45970786,  0.3401268 ,\n",
       "        0.12269896,  0.14960752,  0.45970786,  0.27637742,  0.88892319,\n",
       "        0.44590879,  0.45970786,  0.45970786,  0.45970786,  0.83934263,\n",
       "        0.08725837,  0.45970786,  0.69129784,  0.06128828,  0.12787088])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_output[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>EAP</th>\n",
       "      <th>HPL</th>\n",
       "      <th>MWS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id02310</td>\n",
       "      <td>0.070163</td>\n",
       "      <td>0.228692</td>\n",
       "      <td>0.701145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id24541</td>\n",
       "      <td>0.413122</td>\n",
       "      <td>0.389553</td>\n",
       "      <td>0.197325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id00134</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27757</td>\n",
       "      <td>0.387470</td>\n",
       "      <td>0.052325</td>\n",
       "      <td>0.560205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id04081</td>\n",
       "      <td>0.154854</td>\n",
       "      <td>0.300435</td>\n",
       "      <td>0.544711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id27337</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id24265</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id25917</td>\n",
       "      <td>0.196689</td>\n",
       "      <td>0.140403</td>\n",
       "      <td>0.662908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id04951</td>\n",
       "      <td>0.766070</td>\n",
       "      <td>0.183881</td>\n",
       "      <td>0.050049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id14549</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id22505</td>\n",
       "      <td>0.313328</td>\n",
       "      <td>0.391964</td>\n",
       "      <td>0.294708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id24002</td>\n",
       "      <td>0.245881</td>\n",
       "      <td>0.257073</td>\n",
       "      <td>0.497046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id18982</td>\n",
       "      <td>0.131518</td>\n",
       "      <td>0.030258</td>\n",
       "      <td>0.838224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id15181</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id21888</td>\n",
       "      <td>0.340127</td>\n",
       "      <td>0.384559</td>\n",
       "      <td>0.275314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id12035</td>\n",
       "      <td>0.122699</td>\n",
       "      <td>0.162839</td>\n",
       "      <td>0.714462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id17991</td>\n",
       "      <td>0.149608</td>\n",
       "      <td>0.204890</td>\n",
       "      <td>0.645502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id10707</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id07101</td>\n",
       "      <td>0.276377</td>\n",
       "      <td>0.306508</td>\n",
       "      <td>0.417115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id00345</td>\n",
       "      <td>0.888923</td>\n",
       "      <td>0.046387</td>\n",
       "      <td>0.064690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id05912</td>\n",
       "      <td>0.445909</td>\n",
       "      <td>0.291576</td>\n",
       "      <td>0.262516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id13443</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id09248</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id17542</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id06995</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>0.110761</td>\n",
       "      <td>0.049896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id25159</td>\n",
       "      <td>0.087258</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.759442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id25729</td>\n",
       "      <td>0.459708</td>\n",
       "      <td>0.388333</td>\n",
       "      <td>0.151959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id26949</td>\n",
       "      <td>0.691298</td>\n",
       "      <td>0.244985</td>\n",
       "      <td>0.063717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id27191</td>\n",
       "      <td>0.061288</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>0.874027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id07668</td>\n",
       "      <td>0.127871</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.826734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       EAP       HPL       MWS\n",
       "0   id02310  0.070163  0.228692  0.701145\n",
       "1   id24541  0.413122  0.389553  0.197325\n",
       "2   id00134  0.459708  0.388333  0.151959\n",
       "3   id27757  0.387470  0.052325  0.560205\n",
       "4   id04081  0.154854  0.300435  0.544711\n",
       "5   id27337  0.459708  0.388333  0.151959\n",
       "6   id24265  0.459708  0.388333  0.151959\n",
       "7   id25917  0.196689  0.140403  0.662908\n",
       "8   id04951  0.766070  0.183881  0.050049\n",
       "9   id14549  0.459708  0.388333  0.151959\n",
       "10  id22505  0.313328  0.391964  0.294708\n",
       "11  id24002  0.245881  0.257073  0.497046\n",
       "12  id18982  0.131518  0.030258  0.838224\n",
       "13  id15181  0.459708  0.388333  0.151959\n",
       "14  id21888  0.340127  0.384559  0.275314\n",
       "15  id12035  0.122699  0.162839  0.714462\n",
       "16  id17991  0.149608  0.204890  0.645502\n",
       "17  id10707  0.459708  0.388333  0.151959\n",
       "18  id07101  0.276377  0.306508  0.417115\n",
       "19  id00345  0.888923  0.046387  0.064690\n",
       "20  id05912  0.445909  0.291576  0.262516\n",
       "21  id13443  0.459708  0.388333  0.151959\n",
       "22  id09248  0.459708  0.388333  0.151959\n",
       "23  id17542  0.459708  0.388333  0.151959\n",
       "24  id06995  0.839343  0.110761  0.049896\n",
       "25  id25159  0.087258  0.153300  0.759442\n",
       "26  id25729  0.459708  0.388333  0.151959\n",
       "27  id26949  0.691298  0.244985  0.063717\n",
       "28  id27191  0.061288  0.064685  0.874027\n",
       "29  id07668  0.127871  0.045395  0.826734"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submit = pd.DataFrame(columns = ['id',\"EAP\",\"HPL\",\"MWS\"])\n",
    "df_submit['id'] = test['id']\n",
    "df_submit['EAP'] = y_prob_output[:,0]\n",
    "df_submit['HPL'] = y_prob_output[:,1]\n",
    "df_submit['MWS'] = y_prob_output[:,2]\n",
    "df_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "file = open('time.txt','w') \n",
    "file.write('Congratulations, the project is done! It took: ' + str(end_time - start_time))\n",
    " \n",
    "file.close() \n",
    "#print('Congratulations, the project is done! It took: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
